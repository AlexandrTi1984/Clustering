# -*- coding: utf-8 -*-
"""Кластеризация (анализ записей о болезни сердца).ipynb"

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yjpvmyg0V6_udY3tsmuHssdwKmenua-G

# **Анализ записей о болезни сердца**

### Загрузка библиотек и анализируемого файла
Загружаются необходимые библиотеки.
"""

import pandas as pd
import csv
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.metrics import silhouette_score
from scipy.spatial import distance
from sklearn.cluster import AgglomerativeClustering
from yellowbrick.cluster import KElbowVisualizer
import seaborn as sns

"""Специально для Google Colab загружается необходимый файл csv."""

from google.colab import files
uploaded = files.upload()

"""Читаем файл

"""

dataframe = pd.read_csv("4heart2.csv")

"""# Вывод данных
На экран выводятся первые 10 строк из файла.
"""

dataframe.head(10)

"""# Оценка данных
Далее необходимо оценить данные. Видно, что столбец "DEATH_EVEN"T неправильны, а именно название содержит все заглавные буквы.
Столбец "age" имеет не верный формат
"""

dataframe.info()

"""Для того, чтобы верно ввести текущие названия столбцов для их последующего исправления, применяется метод `columns`, который выводит названия колонок через запятую."""

print(dataframe.columns)

"""# Переименование столбцов
С помощью метода `rename()` столбцы переименовываются, а с помощью метода `info()` проверяется правильность этого переименования.

"""

dataframe.rename(columns={'DEATH_EVENT': 'death_event'}, inplace=True)

print(dataframe.info())

"""Описание колонок:

**age** - возраст: возраст пациента (лет)

**anaemia** -анемия: снижение количества эритроцитов или гемоглобина
(логическое значение)

**creatinine_phosphokinase** - креатининфосфокиназа (КФК): уровень
фермента КФК в крови (мкг/л)

**diabetes**- диабет: если у пациента диабет (логическое
значение)

**ejection_fraction** - фракция выброса: процент крови, покидающей
сердце при каждом сокращении (в процентах)

**high_blood_pressure** -высокое кровяное давление: если у пациента
гипертония (логическое значение)

**platelets** тромбоциты: тромбоциты в крови
(килотромбоциты/ мл)

**serum_creatinine** - креатинин сыворотки: уровень креатинина
сыворотки в крови (мг/дл)

**serum_sodium** - натрий сыворотки: уровень натрия сыворотки в
крови (мэкв/л)

**sex** - пол: женщина или мужчина (бинарный) . Принимаем - Женщина:0 Мужчина: 1

**smoking** - курение: если пациент курит или нет
(логическое)

**time** - время: период наблюдения (дни)

**death_event** - событие смерти: если пациент умер в течение
периода наблюдения (логическое значение)

Далее необходимо проверить, есть ли пропуски в данных, с помощью метода `df.isna().sum()`. Видно, что пропуски отсутствуют, а значит, можно приступать к поиску дубликатов.
"""

print(dataframe.isna().sum())
#fillna(0)
#dropna

"""# Поиск неявных дубликатов и их удаление
Явные дубликаты рациональнее удалять уже после устранения неявных, а именно замены, объектов, имеющих немного отличающиеся названия, но при этом являющихся одним и тем же объекктом по сути.
С помощью метода `unique` и `sort` на экран выводятся все, что есть в столбце "пол" по возрастанию. Сортировка нужна, чтобы было легче искать дубликаты. Некорректных значений нигде обнаружено. Видно, что тип данных в столбце **month_to_end_contract** не целочисленный. Это будет исправлено позже.

"""

dataframe['sex'].unique()

for Name, values in dataframe.iteritems():
  print(Name)
  gen = dataframe[Name].unique()
  gen.sort()
  print(gen, '\n')

"""# Поиск явных дубликатов и их удаление
Производится проверка на наличие явных дубликатов,  и таковых обнаружено не было.
"""

print(dataframe.duplicated().sum())

"""# Изменение типов данных столбцов
С помощью метода `df.dtypes` производится проверка типов данных столбцов.
"""

print(dataframe.dtypes)
# str - object

"""Необходимо поменять тип данных столбца "age" и "platelets" на целочисленный, а после ещё раз проверить правильность."""

dataframe['age'] = dataframe['age'].astype(int)
dataframe['platelets'] = dataframe['platelets'].astype(int)
print(dataframe.dtypes)

"""# Кластеризация
## Иерархический агломеративный метод

Для кластеризации необходимо убрать целевой столбец **death_event**.
"""

y = dataframe['death_event'].values
df = dataframe.drop(columns = ["death_event"])

df

"""Создаётся объект класса scaler, далее он обучается по текущему набору данных, а после данные стандартизируются."""

scaler = StandardScaler() #объект
scaler.fit(df) # обучение
X_sc = scaler.transform(df) # преобразование

X_sc

"""По этим данным строится дендрограмма."""

linked = linkage(X_sc, method = 'ward')
plt.figure(figsize=(15, 10))
dendrogram(linked, orientation='top', truncate_mode = "lastp")
plt.title('Иерархическая кластеризация для анализа записей о болезни сердца')
plt.show()

"""Оптимальное число кластеров, судя по дендрограмме - 4. Некоторые значения встречаются в разных кластерах. Из этого следует, что текущие данные невозможно распределить по однозначно определённым кластерам, а, значит, могут быть получены неверные результаты.

Агломеративная кластеризация, получаем метки (число кластеров задали 4)
"""

# Воспроизведем результат объекдинения данных в кластеры
cluster = AgglomerativeClustering(n_clusters=4,linkage='ward')
labs = cluster.fit_predict(X_sc)
print(labs.tolist())

"""добавляем столбец, где у каждой строки будет метка кластера (всего 4)

"""

df["cluster_ag"] = labs
df.head(10)

"""С помощью сводной таблицы считаем среднее по каждому кластеру и каждому столбцу, можем делать выводы:

1.Средний возраст пациентов в первых трёх кластерах практически одинаковый. В четвертом кластере он самый высокий.

2.Во втором кластере находятся пациенты не страдающие анемией.

3.В третьем кластере находятся пациенты  с повышенным креатининфосфокиназой.

4.В первом кластере больше всего людей с сахарным диабетом.

4.В первом и четвертом кластерах у пациентов наблюдается фракция выброса выше, чем у пациентов из второго и третьего кластера.

5.Высокое кровяное давление (гипертония) наблюдается у пациантов из первого, второго и четвертого кластеров.

6.В первом кластере находятся некурящие пациенты.

7.Пациенты из первого и второго кластера находятся под наблюдением более 130 дней.


"""

df.pivot_table(index= ["cluster_ag"], aggfunc="mean"
                           )

"""## Метод k-средних

### Выбор оптимального количества кластеров
Просматривается, какое количество кластеров покажет метод локтя.
"""

model = AgglomerativeClustering()
visualizer = KElbowVisualizer(model, k=(1,11), timings=False)
visualizer.fit(df)
visualizer.show()

"""Метод локтя показал, что оптимальным числом кластеров является 4.

**Проверяется, для какого количества кластеров кластеризация будет наиболее качественной.**

Задаётся количество кластеров, равное 4, а далее изучается набор данных.
"""

km = KMeans(n_clusters=4,random_state=0) #задаем количество кластеров
km.fit(X_sc)

"""Записывается список того, какие строки из набора данных принадлежат определённому кластеру."""

label = km.fit_predict(X_sc)
print(label.tolist())

"""Задаётся походящая метрика."""

silhouette_score(X_sc, label)

"""Задаётся количество кластеров, равное 3, а далее изучается набор данных."""

km = KMeans(n_clusters=3,random_state=0) #задаем количество кластеров
km.fit(X_sc)

"""Записывается список того, какие строки из набора данных принадлежат определённому кластеру."""

label = km.fit_predict(X_sc)
print(label.tolist())

"""Задаётся походящая метрика."""

silhouette_score(X_sc, label)

"""Задаётся количество кластеров, равное 2, а далее изучается набор данных."""

kmeans = KMeans(n_clusters=2,random_state=0) #задаем количество кластеров
kmeans.fit(X_sc)

"""Записывается список того, какие строки из набора данных принадлежат определённому кластеру."""

labels = kmeans.fit_predict(X_sc) # получение меток классов для каждой строки
print(labels.tolist())

"""Задаётся походящая метрика."""

silhouette_score(X_sc, labels)

"""По метрикам видно, что кластеризация ни в одном из случаев не может быть проведена качественно, однако деление на 2 кластера показало наиболее лучший результат. Именно такое количество кластеров будет задаваться для метода k-средних.

Выводятся центроиды кластеров.
"""

print(kmeans.cluster_centers_)

"""Вычисляется Евклидово расстояние между кластерами, и оно записывается в матрицу, где элемент <i>a<sub>ij</sub></i> матрицы - Евклидово расстояние между кластерами i и j соответственно."""

matr = [[0 for column in range(2)] for row in range(2)]
for i in range(2):  # номер кластера
    for j in range(2):  # расстояние до j-го кластера
        square = 0
        for k in range(12):  # изменено с 13 на 12
            square += np.square(kmeans.cluster_centers_[i][k] - kmeans.cluster_centers_[j][k])
        matr[i][j] = np.sqrt(square)

for i in range(2):
    print(matr[i])

"""В набор данных добавляется ещё один столбец - **cluster**, который показывает, к какому из двух кластеров принадлежит данная строка. Также выводятся первые 5 строк набора данных, чтобы убедиться, что этот столбец добавлен."""

df["cluster"] = labels.tolist()
df.head(5)

"""Средние значения по каждому кластеру по сводной таблице"""

df.pivot_table(index= ["cluster"], aggfunc="mean"
                           )

df.describe()

"""Строится график деления пациентов по столбцу «событие смерти»."""

sns.pairplot(dataframe, hue = 'death_event')

"""Исходя из графика, нельзя точно определить, какие именно признаки оказывают наибольшее влияние на признак.

Для понимания того, какие значения столбцов есть в 1 кластере, создаётся набор данных только по строкам, принадлежащим к этому кластеру.
"""

df0 = df
df0.query('cluster == 0', inplace = True)
df0 = df0.reset_index()
df0.head(5)

"""Строятся графики размаха по каждому из столбцов этого набора данных."""

sns.pairplot(df0)

"""С помощью метода `describe()` просматриваются средние значения по каждому из столбцов, а также их средние отклонения."""

df0.describe()

"""Видно, что большая часть пациентов из этого кластера в возрасте 61 год. у 35% посетителей есть сахарный диабет, и у 39,5% анемия, и 47,9% - курящие.

Т.к. раннее использованный метод метод `query()` повлиял на количество строк, то стоит прочитать данные из файла ещё раз и обработать их, а после создать ещё один набор данных только по 2 кластеру.
"""

df1 = pd.read_csv(open("4heart2.csv", 'rb'))
dataframe.rename(columns={'DEATH_EVENT': 'death_event'}, inplace=True)
dataframe['age'] = dataframe['age'].astype(int)
dataframe['platelets'] = dataframe['platelets'].astype(int)
df1 = dataframe .drop(columns = ["death_event"])
df1["cluster"] = labels.tolist()
df1.query('cluster == 1', inplace = True)
df1 = df1.reset_index()
df1.head(5)

"""Строятся графики размаха по каждому из столбцов этого набора данных."""

sns.pairplot(df1)

df1.describe()

"""Видно, что у 53% пациентов сахарный диабет, пациенты не курящие женщины, 49,5% пациентов страдают анемией.

# Вывод
Данные представляли набор сведений о записях о болезнях сердца с указанием их age - возраста пациента, sex - пола(Женщина: 0 Мужчина: 1), smoking - курения, anaemia -анемия, creatinine_phosphokinase - креатининфосфокиназа, diabetes- диабет, ejection_fraction - фракция выброса, high_blood_pressure -высокое кровяное давление, platelets тромбоциты, serum_creatinine - креатинин сыворотки, serum_sodium - натрий сыворотки, time - период наблюдения (дни), death_event - событие смерти.

Была осуществлена предварительная обработка данных csv-файла, а именно: названия столбцов стали начинаться только со строчных букв, были осуществлены проверки на наличие пропусков и дубликатов, но таковых обнаружено не было. Был изменён тип данных столбца **age** с типа данных с плавающей точкой на целочисленный. После этого данные были стандартизированы и разделены на кластеры двумя методами: иерархическим агломеративным методом и методом k средних. Были выявлены признаки, которые оказали наибольшее влияние на выделение кластеров.

Исходя из дендрограммы разделения на кластеры, оптимальным количеством кластеров является 4. Однако метрика силуэта при таком количестве кластеров составляет около 11,5%, что свидетельствет о том, что кластеризация не является качественной. При двух кластеров метрика практически не меняется - около 11,8%, однако этого мало для качественного деления на кластеры. Из дендрограммы стало видно, что некоторые строчки содержатся в разных кластерах, а, следовательно, данные трудно однозначно разделить на кластеры. На выделение кластеров наибольшее влияние оказали такие признаки, как анемия, диабет, высокое кровяное давление.
"""